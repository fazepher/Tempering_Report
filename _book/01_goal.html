<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.399">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Non-reversible Tempering for multimodal densities - 1&nbsp; The Goal</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link id="quarto-text-highlighting-styles" href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Goal</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Non-reversible Tempering for multimodal densities</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/fazepher/Tempering_Report" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="./Non-reversible-Tempering-for-multimodal-densities.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_goal.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Goal</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Goal</span></h1>
</div>





<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<div class="cell" data-hash="01_goal_cache/html/unnamed-chunk-1_a0484775bec7adaee2018984462fe8d5">

</div>
<p>A common statistical goal is to estimate an expected value of a function <span class="math inline">\(h\)</span> of a random variable <span class="math inline">\(X \in \mathcal{X}\subset\mathbb{R}^d\)</span>:</p>
<p><span class="math display">\[\mathbb{E}_X[h(X)] = \int\limits_{\mathcal{X}} h(x) d\pi_X.\]</span></p>
<p>Despite the aparent simple expression above, these integrals are generally intractable so that one cannot compute them analytically. Furthermore, the dimension <span class="math inline">\(d\)</span> is sufficiently high, as to also render numerical integration infeasable.</p>
<p>Instead, one would like to resort to a <em>Law of Large numbers</em> via Monte Carlo methods. That is, if one is able to simulate in a computer <span class="math inline">\(\lbrace X_s\rbrace_{s=1}^S \overset{iid}{\sim} \pi_X\)</span>, then a reasonable estimator of the target expectation is the sample average since the latter converges to the former as the sample size <span class="math inline">\(S\)</span> grows:</p>
<p><span class="math display">\[\hat{h}_S := \dfrac{1}{S}\sum\limits_{s=1}^S h(X_s) \underset{S\to\infty}{\longrightarrow} \mathbb{E}_X[h(X)].\]</span></p>
<p>This is promising, but one rapidly realizes that for a given <span class="math inline">\(\pi\)</span> of interest it may also be hard to obtain <em>independent</em> samples from it.</p>
<p>Fortunately, it may be easier to generate <em>dependent</em> samples and still use the sample average as an estimator. The idea is that one can construct a <em>Markov Chain</em> whose limiting invariant distribution is <span class="math inline">\(\pi\)</span> and for which an <em>Ergodic Theorem</em> applies to justify our estimation procedure. Indeed, a Markov Chain Monte Carlo estimator, or <strong>MCMC</strong> estimator for short, is constructed by simulating a realization of a Markov Chain <span class="math inline">\(\lbrace X_s\rbrace_{s=1}^S\)</span> such that the following is true:</p>
<p><span class="math display">\[\begin{split}
&amp;X_s \overset{\mathcal{D}}{\underset{s\to\infty}{\longrightarrow}} \pi_X \\
&amp;X_s \sim \pi \Longrightarrow X_{s+1} \sim \pi_X \\
&amp;\hat{h}_S \underset{S\to\infty}{\longrightarrow} \mathbb{E}_X[h(X)]
\end{split}\]</span></p>
<p>As an illustration, let us estimate the mean of a univariate standard normal via one of the basic MCMC algorithms: <strong>Random Walk Metropolis</strong>. The <em>traceplot</em> in the top-left panel of <a href="#fig-rwm-normal">Figure&nbsp;<span>1.1</span></a> shows the evolution of the chain where the horizontal axis represents the sample number and the vertical axis the <span class="math inline">\(x\)</span> state of the chain; we see an oscilating ‘caterpillar’ pattern around the bulk of the distribution and centered at the true mean value of <span class="math inline">\(0\)</span>, signaled by the orange horizontal reference line. On the top-right panel we see the chain’s <em>histogram</em> approximation (blue) to the true density (orange); while not perfect, we can see a decent match. Most importantly to our estimation purposes, we see on the bottom panel the evolution of the <strong>ergodic averages</strong> or cummulative means; indeed there is convergence to the true mean as the chain evolves.</p>
<div class="cell" data-hash="01_goal_cache/html/rwm_normal_chain_85cd4c9fa48df3df8c1bb10dcc96e63d">

</div>
<div class="cell" data-hash="01_goal_cache/html/fig-rwm-normal_9a3a08c39b6d232f7f47a44e8f028a0c">
<div class="cell-output-display">
<div id="fig-rwm-normal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="01_goal_files/figure-html/fig-rwm-normal-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 1.1: Random Walk Metropolis estimation of a univariate standard normal density.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>This method also works for higher dimensions. If we now take a <span class="math inline">\(20\)</span>-dimensional multivariate normal with independent components, we see the same pattern of convergence of the ergodic averages to each of the marginal means (top of <a href="#fig-rwm-mvtnorm">Figure&nbsp;<span>1.2</span></a>). Thinking of a more general expectation of interest, we could for example consider the probability of the first component being bigger than the second component:</p>
<p><span class="math display">\[\text{Pr}[X_1 \geq X_2] = \mathbb{E}_X\left[\,1_{[0,\infty)}(X_1 - X_2)\,\right] = 0.5,\]</span></p>
<p>the convergence is shown in the bottom of <a href="#fig-rwm-mvtnorm">Figure&nbsp;<span>1.2</span></a>.</p>
<div class="cell" data-hash="01_goal_cache/html/rwm_mvtnorm_chain_fbcbf2d3cc4a421ca635c4641242513f">

</div>
<div class="cell" data-hash="01_goal_cache/html/fig-rwm-mvtnorm_9a371587d7486812d31b54f60d1465a8">
<div class="cell-output-display">
<div id="fig-rwm-mvtnorm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="01_goal_files/figure-html/fig-rwm-mvtnorm-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 1.2: Convergence of Random Walk Metropolis ergodic averages to the marginal means of a 20-dimensional multivariate independent normal.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Of course, more complicated distributions lead to more difficult expectations and have lead to a big and exciting area of research aiming to devise better and more efficient MCMC algorithms beyond Random Walk Metropolis. For example, Gibbs Sampling, Elliptic Slice Sampling or Hamiltonian Monte Carlo are all versions of the general Metropolis-Hastings algorithm.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Another generalization to problems where there is change in dimensionality, like model selection, is Reversible Jump MCMC.</p>
<p>While these methods have been highly successful, a situation where they fail badly is whenever the distribution been targeted exhibits multimodality. For example, consider the following mixture of normals in <a href="#fig-dmix_norm">Figure&nbsp;<span>1.3</span></a>.</p>
<div class="cell" data-hash="01_goal_cache/html/fig-dmix_norm_8b155cb8c16fc810e6ff2fff7ea40790">
<div class="cell-output-display">
<div id="fig-dmix_norm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="01_goal_files/figure-html/fig-dmix_norm-1.png" class="img-fluid figure-img" width="396"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 1.3: Density of a mixture of two univariate normals.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The localized and mode-pulling behavior of most common MCMC algorithms prevent them to traverse, in any finite amount of time, the big valley of low probability that separates the modes, effectively trapping any given chain in one of them.</p>
<div class="cell" data-hash="01_goal_cache/html/fig-rwm-mixnorm_40b0d05f2d6a897d1aff30395a37d7ee">
<div class="cell-output-display">
<div id="fig-rwm-mixnorm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="01_goal_files/figure-html/fig-rwm-mixnorm-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 1.4: Random Walk Metropolis biased estimation under a mixture target density with well separated modes.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>If the distributions were flatter, and there would be more bridging mass between the modes, then the same algorithm would be much better behaved and if tuned properly would have no major issues in this simple setting. For example, just letting the chains run longer for the alternative model with parameter <span class="math inline">\(\beta=0.05\)</span>, yields the following:</p>
<div class="cell" data-hash="01_goal_cache/html/fig-rwm-mixnorm-temp_a3b5e3b3bd0f32944e409e6582a7eaf8">
<div class="cell-output-display">
<div id="fig-rwm-mixnorm-temp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="01_goal_files/figure-html/fig-rwm-mixnorm-temp-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 1.5: Random Walk Metropolis biased estimation under a mixture target density with well separated modes.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Gains could be made with more careful tunning. However, what this example illustrates is that flatter densities are easier to explore for MCMC methods and help them escape local mode traps. This property leads to the Simulated Tempering algorithm.</p>


<section class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>It is well documented that the growth of MCMC statistical methodology started with Gibbs Sampling and the availability of software like BUGS, which has continued and expanded to tools like JAGS, Stan, PyMC, BlackJAX or Turing<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>