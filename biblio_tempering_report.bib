
@book{Azzalini13,
  title = {The {{Skew-Normal}} and {{Related Families}}},
  author = {Azzalini, Adelchi},
  year = {2013},
  series = {Institute of {{Mathematical Statistics Monographs}}},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781139248891},
  abstract = {Interest in the skew-normal and related families of distributions has grown enormously over recent years, as theory has advanced, challenges of data have grown, and computational tools have made substantial progress. This comprehensive treatment, blending theory and practice, will be the standard resource for statisticians and applied researchers. Assuming only basic knowledge of (non-measure-theoretic) probability and statistical inference, the book is accessible to the wide range of researchers who use statistical modelling techniques. Guiding readers through the main concepts and results, it covers both the probability and the statistics sides of the subject, in the univariate and multivariate settings. The theoretical development is complemented by numerous illustrations and applications to a range of fields including quantitative finance, medical statistics, environmental risk studies, and industrial and business efficiency. The author's freely available R package sn, available from CRAN, equips readers to put the methods into action with their own data.},
  isbn = {978-1-107-02927-9},
  file = {/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families10.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families11.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families12.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families13.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families14.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families15.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families16.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families2.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families3.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families4.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families5.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families6.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families7.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families8.pdf;/Users/fazepher/Dropbox/Zotero/Azzalini/Azzalini_2013_The_Skew-Normal_and_Related_Families9.pdf}
}

@article{Betancourt19,
  title = {The {{Convergence}} of {{Markov Chain Monte Carlo Methods}}: {{From}} the {{Metropolis Method}} to {{Hamiltonian Monte Carlo}}},
  shorttitle = {The {{Convergence}} of {{Markov Chain Monte Carlo Methods}}},
  author = {Betancourt, Michael},
  year = {2019},
  journal = {Annalen der Physik},
  volume = {531},
  number = {3},
  pages = {1700214},
  issn = {1521-3889},
  doi = {10.1002/andp.201700214},
  abstract = {From its inception in the 1950s to the modern frontiers of applied statistics, Markov chain Monte Carlo has been one of the most ubiquitous and successful methods in statistical computing. The development of the method in that time has been fueled by not only increasingly difficult problems but also novel techniques adopted from physics. Here, the history of Markov chain Monte Carlo is reviewed from its inception with the Metropolis method to the contemporary state-of-the-art in Hamiltonian Monte Carlo, focusing on the evolving interplay between the statistical and physical perspectives of the method.},
  langid = {english},
  keywords = {Hamiltonian Monte Carlo,Markov chain Monte Carlo,molecular dynamics,Monte Carlo},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/andp.201700214}
}

@misc{Betancourt20a,
  title = {Markov {{Chain Monte Carlo}}},
  author = {Betancourt, Michael},
  year = {2020},
  month = may,
  howpublished = {https://betanalpha.github.io/assets/case\_studies/markov\_chain\_monte\_carlo.html},
  annotation = {Retrieved from https://github.com/betanalpha/knitr\_case\_studies/tree/master/markov\_chain\_monte\_carlo, commit b474ec1a5a79347f7c9634376c866fe3294d657a},
  file = {/Users/fazepher/Dropbox/Zotero/Betancourt/Betancourt_2020_Markov_Chain_Monte_Carlo.html}
}

@incollection{Changye.Robert20,
  title = {Markov {{Chain Monte Carlo Algorithms}} for {{Bayesian Computation}}, a {{Survey}} and {{Some Generalisation}}},
  booktitle = {Case {{Studies}} in {{Applied Bayesian Data Science}}: {{CIRM Jean-Morlet Chair}}, {{Fall}} 2018},
  author = {Changye, Wu and Robert, Christian P.},
  editor = {Mengersen, Kerrie L. and Pudlo, Pierre and Robert, Christian P.},
  year = {2020},
  series = {Lecture {{Notes}} in {{Mathematics}}},
  pages = {89--119},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-42553-1_4},
  abstract = {This chapter briefly recalls the major simulation based methods for conducting Bayesian computation, before focusing on partly deterministic Markov processes and a novel modification of the bouncy particle sampler that offers an interesting alternative when dealing with large datasets.},
  isbn = {978-3-030-42553-1},
  langid = {english},
  keywords = {Big Data,Bouncy particle sampler,MCMC algorithms,Monte Carlo methods,PDMP},
  file = {/Users/fazepher/Dropbox/Zotero/Changye_Robert/Changye_Robert_2020_Markov_Chain_Monte_Carlo_Algorithms_for_Bayesian_Computation,_a_Survey_and_Some.pdf}
}

@article{Chib.Greenberg95,
  title = {Understanding the {{Metropolis-Hastings Algorithm}}},
  author = {Chib, Siddhartha and Greenberg, Edward},
  year = {1995},
  journal = {The American Statistician},
  volume = {49},
  number = {4},
  pages = {327--335},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0003-1305},
  doi = {10.2307/2684568},
  abstract = {We provide a detailed, introductory exposition of the Metropolis-Hastings algorithm, a powerful Markov chain method to simulate multivariate distributions. A simple, intuitive derivation of this method is given along with guidance on implementation. Also discussed are two applications of the algorithm, one for implementing acceptance-rejection sampling when a blanketing function is not available and the other for implementing the algorithm with block-at-a-time scans. In the latter situation, many different algorithms, including the Gibbs sampler, are shown to be special cases of the Metropolis-Hastings algorithm. The methods are illustrated with examples.},
  file = {/Users/fazepher/Dropbox/Zotero/Chib_Greenberg/Chib_Greenberg_1995_Understanding_the_Metropolis-Hastings_Algorithm.pdf}
}

@article{Cowles.Carlin96,
  title = {Markov {{Chain Monte Carlo Convergence Diagnostics}}: {{A Comparative Review}}},
  shorttitle = {Markov {{Chain Monte Carlo Convergence Diagnostics}}},
  author = {Cowles, Mary Kathryn and Carlin, Bradley P.},
  year = {1996},
  journal = {Journal of the American Statistical Association},
  volume = {91},
  number = {434},
  pages = {883--904},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  doi = {10.2307/2291683},
  abstract = {A critical issue for users of Markov chain Monte Carlo (MCMC) methods in applications is how to determine when it is safe to stop sampling and use the samples to estimate characteristics of the distribution of interest. Research into methods of computing theoretical convergence bounds holds promise for the future but to date has yielded relatively little of practical use in applied work. Consequently, most MCMC users address the convergence problem by applying diagnostic tools to the output produced by running their samplers. After giving a brief overview of the area, we provide an expository review of 13 convergence diagnostics, describing the theoretical basis and practical implementation of each. We then compare their performance in two simple models and conclude that all of the methods can fail to detect the sorts of convergence failure that they were designed to identify. We thus recommend a combination of strategies aimed at evaluating and accelerating MCMC sampler convergence, including applying diagnostic procedures to a small number of parallel chains, monitoring autocorrelations and cross-correlations, and modifying parametrizations or sampling algorithms appropriately. We emphasize, however, that it is not possible to say with certainty that a finite sample from an MCMC algorithm is representative of an underlying stationary distribution.}
}

@incollection{Craiu.Meng11,
  title = {Perfection within {{Reach}}: {{Exact MCMC Sampling}}},
  shorttitle = {Perfection within {{Reach}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Craiu, Radu V. and Meng, Xiao-Li},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {The amount of research done by the Markov chain Monte Carlo (MCMC) community has been very impressive in the last two decades, as testified by this very},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Craiu_Meng/Craiu_Meng_2011_Perfection_within_Reach.pdf}
}

@article{Duane.etal87,
  title = {Hybrid {{Monte Carlo}}},
  author = {Duane, Simon and Kennedy, Anthony D. and Pendleton, Brian J. and Roweth, Duncan},
  year = {1987},
  month = sep,
  journal = {Physics Letters B},
  volume = {195},
  number = {2},
  pages = {216--222},
  issn = {0370-2693},
  doi = {10.1016/0370-2693(87)91197-X},
  abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.},
  langid = {english}
}

@article{Dunson.Johndrow20,
  title = {The {{Hastings}} Algorithm at Fifty},
  author = {Dunson, D B and Johndrow, J E},
  year = {2020},
  month = mar,
  journal = {Biometrika},
  volume = {107},
  number = {1},
  pages = {1--23},
  issn = {0006-3444},
  doi = {10.1093/biomet/asz066},
  abstract = {In a 1970 Biometrika paper, W. K. Hastings developed a broad class of Markov chain algorithms for sampling from probability distributions that are difficult to sample from directly. The algorithm draws a candidate value from a proposal distribution and accepts the candidate with a probability that can be computed using only the unnormalized density of the target distribution, allowing one to sample from distributions known only up to a constant of proportionality. The stationary distribution of the corresponding Markov chain is the target distribution one is attempting to sample from. The Hastings algorithm generalizes the Metropolis algorithm to allow a much broader class of proposal distributions instead of just symmetric cases. An important class of applications for the Hastings algorithm corresponds to sampling from Bayesian posterior distributions, which have densities given by a prior density multiplied by a likelihood function and divided by a normalizing constant equal to the marginal likelihood. The marginal likelihood is typically intractable, presenting a fundamental barrier to implementation in Bayesian statistics. This barrier can be overcome by Markov chain Monte Carlo sampling algorithms. Amazingly, even after 50 years, the majority of algorithms used in practice today involve the Hastings algorithm. This article provides a brief celebration of the continuing impact of this ingenious algorithm on the 50th anniversary of its publication.}
}

@article{Earl.Deem05,
  title = {Parallel Tempering: {{Theory}}, Applications, and New Perspectives},
  shorttitle = {Parallel Tempering},
  author = {Earl, David J. and Deem, Michael W.},
  year = {2005},
  journal = {Physical Chemistry Chemical Physics},
  volume = {7},
  number = {23},
  pages = {3910},
  issn = {1463-9076, 1463-9084},
  doi = {10.1039/b509983h},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Earl_Deem/Earl_Deem_2005_Parallel_tempering.pdf}
}

@book{Everitt.Jenkins22,
  title = {Computer {{Intensive Statistics}}},
  shorttitle = {Computer {{Intensive Statistics}}},
  author = {Everitt, Richard and Jenkins, Paul A.},
  year = {2022},
  month = jul,
  series = {{{APTS}}},
  address = {{Nottingham}},
  file = {/Users/fazepher/Dropbox/Zotero/Everitt_Jenkins/Everitt_Jenkins_2022_Computer_Intensive_Statistics.pdf}
}

@incollection{Fan.Sisson11,
  title = {Reversible {{Jump MCMC}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Fan, Yanan and Sisson, Scott A.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {The reversible jump Markov chain Monte Carlo (MCMC) sampler (Green, 1995) provides a general framework for Markov chain Monte Carlo simulation in which the dimension of the parameter space can vary between iterates of the Markov chain. The reversible jump sampler can be viewed as an extension of the Metropolis-Hastings algorithm onto more general state spaces. To understand this in a Bayesian modeling context, suppose that for observed data x wehavea countable collectionof candidatemodelsM = \{M1,M2, . . .\} indexedbyaparameter k {$\in$} K. The index k can be considered as an auxiliarymodel indicator variable, such thatMk{${'}$} denotes themodel where k = k{${'}$}. EachmodelMk has an nk-dimensional vector of unknown parameters, \texttheta k {$\in$} Rnk , where nk can take different values for different models k {$\in$} K. The joint posterior distribution of (k, \texttheta k) given observed data, x, is obtained as the product of the likelihood, L(x | k, \texttheta k), and the joint prior, p(k, \texttheta k) = p(\texttheta k | k)p(k), constructed from the prior distribution of \texttheta k under model Mk , and the prior for the model indicator k (i.e. the prior for model Mk). Hence, the joint posterior is{$\pi$}(k, \texttheta k | x) = L(x | k, \texttheta k)p(\texttheta k | k)p(k){$\sum$} k{${'}\in$}K{$\int$} R nk{${'}$} L(x | k{${'}$}, \texttheta{${'}$}k{${'}$})p(\texttheta{${'}$}k{${'}$} | k{${'}$})p(k{${'}$})d\texttheta{${'}$}k{${'}$}. (3.1)The reversible jump algorithm uses the joint posterior distribution in Equation 3.1 as the target of an MCMC sampler over the state space {$\Theta$} = {$\bigcup$}k{$\in$}K(\{k\} \texttimes{} Rnk ), where the states of the Markov chain are of the form (k, \texttheta k), the dimension of which can vary over the state space. Accordingly, from the output of a single Markov chain sampler, the user is able to obtain a full probabilistic description of the posterior probabilities of each model having observed the data, x, in addition to the posterior distributions of the individual models. This chapter aims to provide an overview of the reversible jump sampler. Wewill outlinethe sampler's theoretical underpinnings, present the latest and most popular techniques for enhancing algorithmperformance, and discuss the analysis of sampler output. Through the use of numerous worked examples it is hoped that the reader will gain a broad appreciation of the issues involved in multi-model simulation, and the confidence to implement reversible jump samplers in the course of their own studies.},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Fan_Sisson/Fan_Sisson_2011_Reversible_Jump_MCMC.pdf}
}

@incollection{Flegal.Jones11,
  title = {Implementing {{MCMC}}: {{Estimating}} with {{Confidence}}},
  shorttitle = {Implementing {{MCMC}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Flegal, James M. and Jones, Galin L.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Our goal is to introduce some of the tools useful for analyzing the output of a Markov chain Monte Carlo (MCMC) simulation. In particular, we focus on},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Flegal_Jones/Flegal_Jones_2011_Implementing_MCMC.pdf}
}

@phdthesis{Flegal08,
  title = {Monte {{Carlo Standard Errors}} for {{Markov Chain Monte Carlo}}},
  author = {Flegal, James Marshall},
  year = {2008},
  month = jul,
  langid = {english},
  school = {University of Minnesota},
  file = {/Users/fazepher/Dropbox/Zotero/Flegal/Flegal_2008_Monte_Carlo_Standard_Errors_for_Markov_Chain_Monte_Carlo.pdf}
}

@article{Gelfand.Smith90,
  title = {Sampling-{{Based Approaches}} to {{Calculating Marginal Densities}}},
  author = {Gelfand, Alan E. and Smith, Adrian F. M.},
  year = {1990},
  journal = {Journal of the American Statistical Association},
  volume = {85},
  number = {410},
  pages = {398--409},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  doi = {10.2307/2289776},
  abstract = {Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated.},
  file = {/Users/fazepher/Dropbox/Zotero/Gelfand_Smith/Gelfand_Smith_1990_Sampling-Based_Approaches_to_Calculating_Marginal_Densities.pdf}
}

@inproceedings{Gelman.etal94,
  title = {Efficient {{Metropolis Jumping Rules}}},
  booktitle = {Bayesian {{Statistics}} 5},
  author = {Gelman, Andrew and Roberts, Gareth O. and Gilks, Walter R.},
  year = {1994},
  month = jun,
  pages = {599--607},
  publisher = {{Oxford University Press}},
  address = {{Valencia, Spain}},
  file = {/Users/fazepher/Dropbox/Zotero/Gelman EtAl/Gelman_EtAl_1994_Efficient_Metropolis_Jumping_Rules.pdf}
}

@article{Gelman.Rubin92,
  title = {Inference from {{Iterative Simulation Using Multiple Sequences}}},
  author = {Gelman, Andrew and Rubin, Donald B.},
  year = {1992},
  journal = {Statistical Science},
  volume = {7},
  number = {4},
  pages = {457--472},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237},
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  file = {/Users/fazepher/Dropbox/Zotero/Gelman_Rubin/Gelman_Rubin_1992_Inference_from_Iterative_Simulation_Using_Multiple_Sequences.pdf}
}

@incollection{Gelman.Shirley11,
  title = {Inference from {{Simulations}} and {{Monitoring Convergence}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Gelman, Andrew and Shirley, Kenneth},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Constructing efficient iterative simulation algorithms can be difficult, but inference and monitoring convergence are relatively easy. We first give our},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Gelman_Shirley/Gelman_Shirley_2011_Inference_from_Simulations_and_Monitoring_Convergence.pdf}
}

@article{Geman.Geman84,
  title = {Stochastic {{Relaxation}}, {{Gibbs Distributions}}, and the {{Bayesian Restoration}} of {{Images}}},
  author = {Geman, Stuart and Geman, Donald},
  year = {1984},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-6},
  number = {6},
  pages = {721--741},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.1984.4767596},
  abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution}
}

@article{Geyer05,
  title = {Markov {{Chain Monte Carlo Lecture Notes}}},
  author = {Geyer, Charles J},
  year = {2005},
  month = nov,
  pages = {166},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Geyer/Geyer_Markov_Chain_Monte_Carlo_Lecture_Notes.pdf}
}

@incollection{Geyer11,
  title = {Introduction to {{Markov Chain Monte Carlo}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Geyer, Charles J.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Despite a few notable uses of simulation of random processes in the pre-computer era (Hammersley and Handscomb, 1964, Section 1.2; Stigler, 2002, Chapter 7), practical widespread use of simulation had to await the invention of computers. Almost as soon as computers were invented, they were used for simulation (Hammersley and Handscomb, 1964, Section 1.2). The name ``Monte Carlo'' started as cuteness-gambling was then (around 1950) illegal in most places, and the casino at Monte Carlo was the most famous in the world-but it soon became a colorless technical term for simulation of random processes. Markov chain Monte Carlo (MCMC) was invented soon after ordinary Monte Carlo atLos Alamos, one of the few places where computers were available at the time. Metropolis et al. (1953){${_\ast}$} simulated a liquid in equilibrium with its gas phase. The obvious way to find out about the thermodynamic equilibrium is to simulate the dynamics of the system, and let it run until it reaches equilibrium. The tour de force was their realization that they did not need to simulate the exact dynamics; they only needed to simulate someMarkov chain having the same equilibrium distribution. Simulations following the scheme of Metropolis et al. (1953) are said to use the Metropolis algorithm. As computers became more widely available, the Metropolis algorithm was widely used by chemists and physicists, but it did not become widely known among statisticians until after 1990. Hastings (1970) generalized the Metropolis algorithm, and simulations following his scheme are said to use the Metropolis-Hastings algorithm. A special case of the Metropolis-Hastings algorithm was introduced by Geman and Geman (1984), apparently without knowledge of earlier work. Simulations following their scheme are said to use the Gibbs sampler. Much of Geman and Geman (1984) discusses optimization to find the posterior mode rather than simulation, and it took some time for it to be understood in the spatial statistics community that the Gibbs sampler simulated the posterior distribution, thus enabling full Bayesian inference of all kinds. Amethodology that was later seen to be very similar to the Gibbs sampler was introduced by Tanner and Wong (1987), again apparently without knowledge of earlier work. To this day, some refer to the Gibbs sampler as ``data augmentation'' following these authors. Gelfand and Smith (1990)made thewider Bayesian community aware of theGibbs sampler, which up to that time had been known only in the spatial statistics community. Then it took off; as of this writing, a search for Gelfand and Smith (1990) on Google Scholar yields 4003 links to other works. It was rapidly realized that most Bayesian inference couldresearchers to properly understand the theory of MCMC (Geyer, 1992; Tierney, 1994) and that all of the aforementionedworkwas a special case of the notion ofMCMC. Green (1995) generalized theMetropolis-Hastings algorithm, asmuch as it can be generalized.Although this terminology is not widely used, we say that simulations following his scheme use the Metropolis-Hastings-Green algorithm. MCMC is not used only for Bayesian inference. Likelihood inference in caseswhere the likelihood cannot be calculated explicitly due tomissing data or complex dependence can also useMCMC (Geyer, 1994, 1999; Geyer and Thompson, 1992, 1995, and references cited therein).},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Geyer/Geyer_2011_Introduction_to_Markov_Chain_Monte_Carlo.pdf}
}

@incollection{Geyer11a,
  title = {Importance {{Sampling}}, {{Simulated Tempering}}, and {{Umbrella Sampling}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Geyer, Charles J.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {The importance of so-called importance sampling inMarkov chainMonteCarlo (MCMC) is not what gives it that name. It is the idea that ``any sample can come from},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Geyer/Geyer_2011_Importance_Sampling,_Simulated_Tempering,_and_Umbrella_Sampling.pdf}
}

@inproceedings{Geyer91,
  title = {Markov {{Chain Monte Carlo Maximum Likelihood}}},
  author = {Geyer, Charles J.},
  year = {1991},
  publisher = {{Interface Foundation of North America}},
  abstract = {Markov chain Monte Carlo (e. g., the Metropolis algorithm and Gibbs sampler) is a general tool for simulation of complex stochastic processes useful in   many types of statistical inference. The basics of Markov chain Monte Carlo are   reviewed, including choice of algorithms and variance estimation, and some new  methods are introduced. The use of Markov chain Monte Carlo for maximum likelihood estimation is explained, and its performance is compared with maximum pseudo  likelihood estimation.},
  langid = {american},
  annotation = {Accepted: 2010-02-24T20:38:06Z},
  file = {/Users/fazepher/Dropbox/Zotero/Geyer/Geyer_1991_Markov_Chain_Monte_Carlo_Maximum_Likelihood.pdf}
}

@article{Green.etal15,
  title = {Bayesian Computation: A Summary of the Current State, and Samples Backwards and Forwards},
  shorttitle = {Bayesian Computation},
  author = {Green, Peter J. and {\L}atuszy{\'n}ski, Krzysztof and Pereyra, Marcelo and Robert, Christian P.},
  year = {2015},
  month = jul,
  journal = {Statistics and Computing},
  volume = {25},
  number = {4},
  pages = {835--862},
  issn = {1573-1375},
  doi = {10.1007/s11222-015-9574-5},
  abstract = {Recent decades have seen enormous improvements in computational inference for statistical models; there have been competitive continual enhancements in a wide range of computational tools. In Bayesian inference, first and foremost, MCMC techniques have continued to evolve, moving from random walk proposals to Langevin drift, to Hamiltonian Monte Carlo, and so on, with both theoretical and algorithmic innovations opening new opportunities to practitioners. However, this impressive evolution in capacity is confronted by an even steeper increase in the complexity of the datasets to be addressed. The difficulties of modelling and then handling ever more complex datasets most likely call for a new type of tool for computational inference that dramatically reduces the dimension and size of the raw data while capturing its essential aspects. Approximate models and algorithms may thus be at the core of the next computational revolution.},
  langid = {english},
  keywords = {ABC techniques,Bayesian analysis,MCMC algorithms,Optimisation},
  file = {/Users/fazepher/Dropbox/Zotero/Green EtAl/Green_EtAl_2015_Bayesian_computation.pdf}
}

@article{Hastings70,
  title = {Monte {{Carlo Sampling Methods Using Markov Chains}} and {{Their Applications}}},
  author = {Hastings, Wilfred K.},
  year = {1970},
  journal = {Biometrika},
  volume = {57},
  number = {1},
  pages = {97--109},
  publisher = {{[Oxford University Press, Biometrika Trust]}},
  issn = {0006-3444},
  doi = {10.2307/2334940},
  abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
  file = {/Users/fazepher/Dropbox/Zotero/Hastings/Hastings_1970_Monte_Carlo_Sampling_Methods_Using_Markov_Chains_and_Their_Applications.pdf}
}

@incollection{Hobert11,
  title = {The {{Data Augmentation Algorithm}}: {{Theory}} and {{Methodology}}},
  shorttitle = {The {{Data Augmentation Algorithm}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Hobert, James P.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Assume that the function fX : Rp \textrightarrow{} [0,{$\infty$}) is a probability density function (pdf). Suppose that g : Rp \textrightarrow{} R is a function of interest and that we want to know},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Hobert/Hobert_2011_The_Data_Augmentation_Algorithm.pdf}
}

@incollection{Huber11,
  title = {Spatial {{Point Processes}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Huber, Mark},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Spatial point processes arise naturally in many contexts, including population studies, forestry, epidemiology, agriculture, and material science; for more},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Huber/Huber_2011_Spatial_Point_Processes.pdf}
}

@book{Liu04,
  title = {Monte {{Carlo Strategies}} in {{Scientific Computing}}},
  author = {Liu, Jun S.},
  year = {2004},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-76371-2},
  isbn = {978-0-387-76369-9 978-0-387-76371-2},
  keywords = {convergence of random variables,Excel,Markov chain,Markov Chains,mathematical statistics,modeling,Monte Carlo Method,optimization,Potential,Probability theory,Random variable,Scientific Computing,statistics},
  file = {/Users/fazepher/Dropbox/Zotero/Liu/Liu_2004_Monte_Carlo_Strategies_in_Scientific_Computing.pdf}
}

@article{Marinari.Parisi92,
  title = {Simulated {{Tempering}}: {{A New Monte Carlo Scheme}}},
  shorttitle = {Simulated {{Tempering}}},
  author = {Marinari, Enzo and Parisi, Giorgio},
  year = {1992},
  month = jul,
  journal = {Europhysics Letters (EPL)},
  volume = {19},
  number = {6},
  pages = {451--458},
  publisher = {{IOP Publishing}},
  issn = {0295-5075},
  doi = {10.1209/0295-5075/19/6/002},
  abstract = {We propose a new global optimization method (Simulated Tempering) for simulating effectively a system with a rough free-energy landscape (i.e., many coexisting states) at finite nonzero temperature. This method is related to simulated annealing, but here the temperature becomes a dynamic variable, and the system is always kept at equilibrium. We analyse the method on the Random Field Ising Model, and we find a dramatic improvement over conventional Metropolis and cluster methods. We analyse and discuss the conditions under which the method has optimal performances.},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Marinari_Parisi/Marinari_Parisi_1992_Simulated_Tempering.pdf;/Users/fazepher/Dropbox/Zotero/Marinari_Parisi/Marinari_Parisi_1992_Simulated_Tempering2.pdf}
}

@article{Metropolis.etal53,
  title = {Equation of {{State Calculations}} by {{Fast Computing Machines}}},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  year = {1953},
  month = jun,
  journal = {The Journal of Chemical Physics},
  volume = {21},
  number = {6},
  pages = {1087--1092},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.1699114},
  file = {/Users/fazepher/Dropbox/Zotero/Metropolis EtAl/Metropolis_EtAl_1953_Equation_of_State_Calculations_by_Fast_Computing_Machines.pdf}
}

@article{Metropolis.Ulam49,
  title = {The {{Monte Carlo Method}}},
  author = {Metropolis, Nicholas and Ulam, Stanis{\l}aw},
  year = {1949},
  journal = {Journal of the American Statistical Association},
  volume = {44},
  number = {247},
  pages = {335--341},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  doi = {10.2307/2280232},
  abstract = {We shall present here the motivation and a general description of a method dealing with a class of problems in mathematical physics. The method is, essentially, a statistical approach to the study of differential equations, or more generally, of integro-differential equations that occur in various branches of the natural sciences.},
  file = {/Users/fazepher/Dropbox/Zotero/Metropolis_Ulam/Metropolis_Ulam_1949_The_Monte_Carlo_Method.pdf}
}

@incollection{Neal11,
  title = {{{MCMC Using Hamiltonian Dynamics}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Neal, Radford M.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Markov chain Monte Carlo (MCMC) originated with the classic paper of Metropolis et al. (1953), where it was used to simulate the distribution of states for a},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Neal/Neal_2011_MCMC_Using_Hamiltonian_Dynamics.pdf}
}

@techreport{Neal93,
  type = {Technical},
  title = {Probabilistic {{Inference Using Markov Chain Monte Carlo Methods}}},
  author = {Neal, Radford M.},
  year = {1993},
  month = sep,
  number = {CRG-TR-93-1},
  pages = {144},
  institution = {{Department of Comupter Science, University of Toronto}},
  file = {/Users/fazepher/Dropbox/Zotero/Neal/Neal_1993_Probabilistic_Inference_Using_Markov_Chain_Monte_Carlo_Methods.pdf}
}

@article{Okabe.etal01,
  title = {Replica-Exchange {{Monte Carlo}} Method for the Isobaric\textendash Isothermal Ensemble},
  author = {Okabe, Tsuneyasu and Kawata, Masaaki and Okamoto, Yuko and Mikami, Masuhiro},
  year = {2001},
  month = mar,
  journal = {Chemical Physics Letters},
  volume = {335},
  number = {5},
  pages = {435--439},
  issn = {0009-2614},
  doi = {10.1016/S0009-2614(01)00055-0},
  abstract = {We propose an extension of replica-exchange Monte Carlo method for canonical ensemble to isothermal\textendash isobaric ensemble as an effective method to search for stable states quickly and widely in complex configuration space. We investigated the efficiency of the new method on a benchmark testing system which consists of 256 Lennard-Jones particles. The new method enables us to shorten dramatically the relaxation time of phase change from liquid structure to crystal structure in comparison with the conventional Monte Carlo method.},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Okabe EtAl/Okabe_EtAl_2001_Replica-exchange_Monte_Carlo_method_for_the_isobaric–isothermal_ensemble.pdf}
}

@book{Robert.Casella04,
  title = {Monte {{Carlo Statistical Methods}}},
  author = {Robert, Christian P. and Casella, George},
  year = {2004},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4757-4145-2},
  isbn = {978-1-4419-1939-7 978-1-4757-4145-2},
  keywords = {algorithms,computer,Importance Sampling,Markov chain,Markov chain Monte Carlo,Mathematica,mathematical statistics,mathematics,optimization,programming,Random variable,Ringe,simulation,statistical inference,statistics},
  file = {/Users/fazepher/Dropbox/Zotero/Robert_Casella/Robert_Casella_2004_Monte_Carlo_Statistical_Methods.pdf}
}

@book{Robert.Casella10,
  title = {Introducing {{Monte Carlo Methods}} with {{R}}},
  author = {Robert, Christian and Casella, George},
  year = {2010},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4419-1576-4},
  isbn = {978-1-4419-1582-5 978-1-4419-1576-4},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Robert_Casella/Robert_Casella_2010_Introducing_Monte_Carlo_Methods_with_R.pdf}
}

@incollection{Robert.Casella11,
  title = {A {{Short History}} of {{MCMC}}: {{Subjective Recollections}} from {{Incomplete Data}}},
  shorttitle = {A {{Short History}} of {{MCMC}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Robert, Christian and Casella, George},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Markov chainMonteCarlo (MCMC)methodshavebeenaround for almost as longasMonte Carlo techniques, even though their impact on statistics was not truly felt until the very early 1990s, except in the specialized fields of spatial statistics and image analysis, where those methods appeared earlier. The emergence of Markov based techniques in physics is a story that remains untold within this survey (see Landau and Binder, 2005). Also, we will not enter into a description of MCMC techniques, unless they have some historical link, as the remainder of this volume covers the technical aspects.Acomprehensive treatment with further references can also be found in Robert and Casella (2004). We will distinguish between the introduction of Metropolis-Hastings based algorithmsand those related to Gibbs sampling, since they each stem from radically different origins, even though their mathematical justification via Markov chain theory is the same. Tracing the development of Monte Carlo methods, we will also briefly mention what we might call the ``second-generation MCMC revolution.'' Starting in the mid to late 1990s, this includes the development of particle filters, reversible jump and perfect sampling, and concludes with more current work on population or sequential Monte Carlo and regeneration and the computing of ``honest'' standard errors. As mentioned above, the realization that Markov chains could be used in a wide varietyof situations only came (tomainstream statisticians)withGelfand and Smith (1990), despite earlier publications in the statistical literature such as Hastings (1970), Geman and Geman (1984), and Tanner and Wong (1987). Several reasons can be advanced: lack of computing machinery (think of the computers of 1970!), or background onMarkov chains, or hesitation to trust in the practicality of themethod. It thus required visionary researchers like Gelfand and Smith to convince the community, supported by papers that demonstrated, through a series of applications, that the method was easy to understand, easy to implement and practical (Gelfand et al., 1990, 1992; Smith and Gelfand, 1992; Wakefield et al., 1994). The rapid emergence of the dedicated BUGS (Bayesian inference using Gibbs sampling) software as early as 1991, when a paper on BUGS was presented at the Valencia meeting, was another compelling argument for adopting, at large, MCMC algorithms.{${_\ast}$}Monte Carlo methods were born in Los Alamos, New Mexico, during World War II, eventually resulting in theMetropolis algorithm in the early 1950s. WhileMonte Carlo methods were in use by that time, MCMC was brought closer to statistical practicality by the work of Hastings in the 1970s. What can be reasonably seen as the first MCMC algorithm is what we now call theMetropolis algorithm, published by Metropolis et al. (1953). It emanates from the same group of scientists who produced the Monte Carlo method, namely the research scientists of Los Alamos, mostly physicists working on mathematical physics and the atomic bomb. MCMC algorithms therefore date back to the same time as the development of regular(MC only) Monte Carlo methods, which are usually traced to Ulam and von Neumann in the late 1940s. StanislawUlam associates the original ideawith an intractable combinatorial computation he attempted in 1946 (calculating the probability of winning at the solitaire card game). This ideawas enthusiastically adopted by John vonNeumann for implementationwith direct applications to neutron diffusion, the name ``Monte Carlo'' being suggested by Nicholas Metropolis. Eckhardt (1987) describes these early Monte Carlo developments, and Hitchcock (2003) gives a brief history of the Metropolis algorithm. These occurrences very closely coincide with the appearance of the very first general-purpose digital computer, the ENIAC,which came to life in February 1946, after three years of construction. The Monte Carlo method was set up by von Neumann, who was using it on thermonuclear and fission problems as early as 1947. That same year, Ulam and vonNeumann invented inversion andaccept-reject techniques (also recounted inEckhardt, 1987) to simulate from nonuniform distributions. Without computers, a rudimentary version invented by Fermi in the 1930s went unrecognized (Metropolis, 1987). Note also that, as early as 1949, a symposiumonMonteCarlowas supported byRand, theNational Bureau of Standards, and theOakRidge laboratory and thatMetropolis andUlam (1949) published the very first paper about the Monte Carlo method.},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Robert_Casella/Robert_Casella_2011_A_Short_History_of_MCMC.pdf}
}

@article{Robert.Casella11a,
  title = {A {{Short History}} of {{Markov Chain Monte Carlo}}: {{Subjective Recollections}} from {{Incomplete Data}}},
  shorttitle = {A {{Short History}} of {{Markov Chain Monte Carlo}}},
  author = {Robert, Christian and Casella, George},
  year = {2011},
  month = feb,
  journal = {Statistical Science},
  volume = {26},
  number = {1},
  pages = {102--115},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/10-STS351},
  abstract = {We attempt to trace the history and development of Markov chain Monte Carlo (MCMC) from its early inception in the late 1940s through its use today. We see how the earlier stages of Monte Carlo (MC, not MCMC) research have led to the algorithms currently in use. More importantly, we see how the development of this methodology has not only changed our solutions to problems, but has changed the way we think about problems.},
  keywords = {Bayesian methods,Gibbs sampling,hierarchical models,Metropolis–Hasting algorithm},
  file = {/Users/fazepher/Dropbox/Zotero/Robert_Casella/Robert_Casella_2011_A_Short_History_of_Markov_Chain_Monte_Carlo.pdf}
}

@incollection{Robert.Changye21,
  title = {Markov {{Chain Monte Carlo Methods}}, {{Survey}} with {{Some Frequent Misunderstandings}}},
  booktitle = {Wiley {{StatsRef}}: {{Statistics Reference Online}}},
  author = {Robert, Christian P. and Changye, Wu},
  year = {2021},
  pages = {1--28},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781118445112.stat08285},
  abstract = {In this article, we review some of the most standard tools used in Bayesian computation, along with vignettes on standard misunderstandings of these approaches taken from Q \& As on the forum Cross-validated answered by the first author.},
  isbn = {978-1-118-44511-2},
  langid = {english},
  keywords = {Bayesian inference,Cross-validated,Gibbs sampler,Hamiltonian,importance sampling,leapfrog integrator,Metropolis-Hastings algorithm,Monte Carlo,optimization,proposal,simulation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118445112.stat08285},
  file = {/Users/fazepher/Dropbox/Zotero/Robert_Changye/Robert_Changye_2021_Markov_Chain_Monte_Carlo_Methods,_Survey_with_Some_Frequent_Misunderstandings.pdf}
}

@article{Robert.etal18,
  title = {Accelerating {{MCMC}} Algorithms},
  author = {Robert, Christian P. and Elvira, V{\'i}ctor and Tawn, Nick and Wu, Changye},
  year = {2018},
  journal = {WIREs Computational Statistics},
  volume = {10},
  number = {5},
  pages = {e1435},
  issn = {1939-0068},
  doi = {10.1002/wics.1435},
  abstract = {Markov chain Monte Carlo algorithms are used to simulate from complex statistical distributions by way of a local exploration of these distributions. This local feature avoids heavy requests on understanding the nature of the target, but it also potentially induces a lengthy exploration of this target, with a requirement on the number of simulations that grows with the dimension of the problem and with the complexity of the data behind it. Several techniques are available toward accelerating the convergence of these Monte Carlo algorithms, either at the exploration level (as in tempering, Hamiltonian Monte Carlo and partly deterministic methods) or at the exploitation level (with Rao\textendash Blackwellization and scalable methods). This article is categorized under: Statistical and Graphical Methods of Data Analysis {$>$} Markov Chain Monte Carlo (MCMC) Algorithms and Computational Methods {$>$} Algorithms Statistical and Graphical Methods of Data Analysis {$>$} Monte Carlo Methods},
  langid = {english},
  keywords = {Bayesian analysis,computational statistics,convergence of algorithms,efficiency of algorithms,Hamiltonian Monte Carlo,Monte Carlo methods,Rao-Blackwellisation,simulation,tempering},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1435},
  file = {/Users/fazepher/Dropbox/Zotero/Robert EtAl/Robert_EtAl_2018_Accelerating_MCMC_algorithms.pdf}
}

@misc{Robert16,
  title = {The {{Metropolis-Hastings}} Algorithm},
  author = {Robert, Christian P.},
  year = {2016},
  month = jan,
  number = {arXiv:1504.01896},
  eprint = {1504.01896},
  eprinttype = {arxiv},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1504.01896},
  abstract = {This short note is a self-contained and basic introduction to the Metropolis-Hastings algorithm, this ubiquitous tool used for producing dependent simulations from an arbitrary distribution. The document illustrates the principles of the methodology on simple examples with R codes and provides references to the recent extensions of the method.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Computation},
  file = {/Users/fazepher/Dropbox/Zotero/Robert/Robert_2016_The_Metropolis-Hastings_algorithm.pdf}
}

@article{Roberts.etal97,
  title = {Weak {{Convergence}} and {{Optimal Scaling}} of {{Random Walk Metropolis Algorithms}}},
  author = {Roberts, Gareth O. and Gelman, Andrew and Gilks, Walter R.},
  year = {1997},
  journal = {The Annals of Applied Probability},
  volume = {7},
  number = {1},
  pages = {110--120},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {1050-5164},
  abstract = {This paper considers the problem of scaling the proposal distribution of a multidimensional random walk Metropolis algorithm in order to maximize the efficiency of the algorithm. The main result is a weak convergence result as the dimension of a sequence of target densities, n, converges to {$\infty$}. When the proposal variance is appropriately scaled according to n, the sequence of stochastic processes formed by the first component of each Markov chain converges to the appropriate limiting Langevin diffusion process. The limiting diffusion approximation admits a straightforward efficiency maximization problem, and the resulting asymptotically optimal policy is related to the asymptotic acceptance rate of proposed moves for the algorithm. The asymptotically optimal acceptance rate is 0.234 under quite general conditions. The main result is proved in the case where the target density has a symmetric product form. Extensions of the result are discussed.},
  file = {/Users/fazepher/Dropbox/Zotero/Roberts EtAl/Roberts_EtAl_1997_Weak_Convergence_and_Optimal_Scaling_of_Random_Walk_Metropolis_Algorithms.pdf}
}

@article{Roberts.Rosenthal01,
  title = {Optimal {{Scaling}} for {{Various Metropolis-Hastings Algorithms}}},
  author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
  year = {2001},
  journal = {Statistical Science},
  volume = {16},
  number = {4},
  pages = {351--367},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237},
  abstract = {We review and extend results related to optimal scaling of Metropolis-Hastings algorithms. We present various theoretical results for the high-dimensional limit. We also present simulation studies which confirm the theoretical results in finite-dimensional contexts.},
  file = {/Users/fazepher/Dropbox/Zotero/Roberts_Rosenthal/Roberts_Rosenthal_2001_Optimal_Scaling_for_Various_Metropolis-Hastings_Algorithms.pdf}
}

@article{Roberts.Tweedie96,
  title = {Geometric {{Convergence}} and {{Central Limit Theorems}} for {{Multidimensional Hastings}} and {{Metropolis Algorithms}}},
  author = {Roberts, Gareth O. and Tweedie, Richard L.},
  year = {1996},
  journal = {Biometrika},
  volume = {83},
  number = {1},
  pages = {95--110},
  publisher = {{[Oxford University Press, Biometrika Trust]}},
  issn = {0006-3444},
  abstract = {We develop results on geometric ergodicity of Markov chains and apply these and other recent results in Markov chain theory to multidimensional Hastings and Metropolis algorithms. For those based on random walk candidate distributions, we find sufficient conditions for moments and moment generating functions to converge at a geometric rate to a prescribed distribution {$\pi$}. By phrasing the conditions in terms of the curvature of the densities we show that the results apply to all distributions with positive densities in a large class which encompasses many commonly-used statistical forms. From these results we develop central limit theorems for the Metropolis algorithm. Converse results, showing non-geometric convergence rates for chains where the rejection rate is not bounded away from unity, are also given; these show that the negative-definiteness property is not redundant.},
  file = {/Users/fazepher/Dropbox/Zotero/Roberts_Tweedie/Roberts_Tweedie_1996_Geometric_Convergence_and_Central_Limit_Theorems_for_Multidimensional_Hastings.pdf}
}

@incollection{Rosenthal11,
  title = {Optimal {{Proposal Distributions}} and {{Adaptive MCMC}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Rosenthal, Jeffrey S.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {TheMetropolis-Hastings algorithm (Metropolis et al., 1953; Hastings, 1970) requires choice of proposal distributions, and it is well known that some},
  isbn = {978-0-429-13850-8},
  file = {/Users/fazepher/Dropbox/Zotero/Rosenthal/Rosenthal_2011_Optimal_Proposal_Distributions_and_Adaptive_MCMC.pdf}
}

@misc{Schwartz21,
  title = {Statistical {{Mechanics}}},
  author = {Schwartz, Matthew},
  year = {2021},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Schwartz/Schwartz_Lecture_1.pdf}
}

@article{Sherlock.Thiery22,
  title = {A Discrete Bouncy Particle Sampler},
  author = {Sherlock, C and Thiery, A H},
  year = {2022},
  month = jun,
  journal = {Biometrika},
  volume = {109},
  number = {2},
  pages = {335--349},
  issn = {1464-3510},
  doi = {10.1093/biomet/asab013},
  abstract = {Most Markov chain Monte Carlo methods operate in discrete time and are reversible with respect to the target probability. Nevertheless, it is now understood that the use of nonreversible Markov chains can be beneficial in many contexts. In particular, the recently proposed bouncy particle sampler leverages a continuous-time and nonreversible Markov process, and empirically shows state-of-the-art performance when used to explore certain probability densities; however, its implementation typically requires the computation of local upper bounds on the gradient of the log target density. We present the discrete bouncy particle sampler, a general algorithm based on a guided random walk, a partial refreshment of direction and a delayed-rejection step. We show that the bouncy particle sampler can be understood as a scaling limit of a special case of our algorithm. In contrast to the bouncy particle sampler, implementing the discrete bouncy particle sampler only requires pointwise evaluation of the target density and its gradient. We propose extensions of the basic algorithm for situations when the exact gradient of the target density is not available. In a Gaussian setting, we establish a scaling limit for the radial process as the dimension increases to infinity. We leverage this result to obtain the theoretical efficiency of the discrete bouncy particle sampler as a function of the partial-refreshment parameter, which leads to a simple and robust tuning criterion. A further analysis in a more general setting suggests that this tuning criterion applies more generally. Theoretical and empirical efficiency curves are then compared for different targets and algorithm variations.}
}

@incollection{Stenning.Dyk21,
  title = {{{BAYESIAN STATISTICAL METHODS FOR ASTRONOMY PART II}}: {{MARKOV CHAIN MONTE CARLO}}},
  shorttitle = {{{BAYESIAN STATISTICAL METHODS FOR ASTRONOMY PART II}}},
  booktitle = {{{BAYESIAN STATISTICAL METHODS FOR ASTRONOMY PART II}}: {{MARKOV CHAIN MONTE CARLO}}},
  author = {Stenning, David C. and van Dyk, David A.},
  year = {2021},
  month = feb,
  pages = {29--58},
  publisher = {{EDP Sciences}},
  doi = {10.1051/978-2-7598-2275-1.c006},
  abstract = {BAYESIAN STATISTICAL METHODS FOR ASTRONOMY PART II: MARKOV CHAIN MONTE CARLO was published in Statistics for Astrophysics on page 29.},
  isbn = {978-2-7598-2275-1},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Stenning_Dyk/Stenning_Dyk_2021_BAYESIAN_STATISTICAL_METHODS_FOR_ASTRONOMY_PART_II.pdf}
}

@phdthesis{Stephens97,
  title = {Bayesian {{Methods}} for {{Mixtures}} of {{Normal Distributions}}},
  author = {Stephens, Matthew},
  year = {1997},
  abstract = {Mixture distributions are typically used to model data in which each observation is assumed to have arisen from one of a number of different groups. They also provide a convenient and flexible class of models for density estimation. While a Bayesian analysis of mixture models has certain advantages over a classical approach, it is not without its problems. In theory quantities of interest may be written down as integrals, but in practice these integrals cannot be done analytically. When the number of groups in the data is assumed known, the Gibbs sampler can be used to perform this integration numerically, but the non-identifiability of the mixture model parameters causes label-switching in the Gibbs sampler output and makes inference for the individual components of the mixture meaningless. We show that the usual method of dealing with this problem (imposing simple identifiability constraints on the mixture model parameters) is sometimes inadequate, and present a more flexible approach to solving this problem, which allows sensible clustering to be performed in a Bayesian context and allows interpretations for groups to be discovered rather than imposed. We illustrate the success of our approach on several examples. When the number of groups in the data is considered unknown more sophisticated methods are required to perform the integration necessary for a Bayesian analysis. One method is described by Richardson and Green (1997), which they apply successfully to univariate data. We describe an alternative method which views the parameters of the model as a (marked) point process, extending methods suggested by Ripley (1977) to create a Markov birth-death process with an appropriate stationary distribution. We apply this method successfully to both univariate and bivariate data. Finally we examine ``on-line'' methods for mixture models, in which the posterior distribution of the parameters is updated as observations arrive sequentially, and are then discarded. We show that the computationally trivial Quasi-Bayes method of Makov and Smith (1977) can be improved upon at the expense of small additional computational complexity.},
  langid = {english},
  school = {University of Oxford},
  file = {/Users/fazepher/Dropbox/Zotero/Stephens/Stephens_1997_Bayesian_Methods_for_Mixtures_of_Normal_Distributions.pdf}
}

@misc{Sutton.etal22,
  title = {Continuously-{{Tempered PDMP Samplers}}},
  author = {Sutton, Matthew and Salomone, Robert and Chevallier, Augustin and Fearnhead, Paul},
  year = {2022},
  month = may,
  number = {arXiv:2205.09559},
  eprint = {2205.09559},
  eprinttype = {arxiv},
  primaryclass = {stat},
  publisher = {{arXiv}},
  abstract = {New sampling algorithms based on simulating continuous-time stochastic processes called piece-wise deterministic Markov processes (PDMPs) have shown considerable promise. However, these methods can struggle to sample from multi-modal or heavy-tailed distributions. We show how tempering ideas can improve the mixing of PDMPs in such cases. We introduce an extended distribution defined over the state of the posterior distribution and an inverse temperature, which interpolates between a tractable distribution when the inverse temperature is 0 and the posterior when the inverse temperature is 1. The marginal distribution of the inverse temperature is a mixture of a continuous distribution on [0,1) and a point mass at 1: which means that we obtain samples when the inverse temperature is 1, and these are draws from the posterior, but sampling algorithms will also explore distributions at lower temperatures which will improve mixing. We show how PDMPs, and particularly the Zig-Zag sampler, can be implemented to sample from such an extended distribution. The resulting algorithm is easy to implement and we show empirically that it can outperform existing PDMP-based samplers on challenging multimodal posteriors.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/fazepher/Dropbox/Zotero/Sutton EtAl/Sutton_EtAl_2022_Continuously-Tempered_PDMP_Samplers.pdf}
}

@article{Swendsen.Wang86,
  title = {Replica {{Monte Carlo Simulation}} of {{Spin-Glasses}}},
  author = {Swendsen, Robert H. and Wang, Jian-Sheng},
  year = {1986},
  month = nov,
  journal = {Physical Review Letters},
  volume = {57},
  number = {21},
  pages = {2607--2609},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.57.2607},
  abstract = {A new Monte Carlo method is presented for simulations of systems with quenched random interactions. The approach greatly reduces the long correlation times characteristic of standard methods, allowing the investigation of lower temperatures with less computer time than previously necessary.},
  file = {/Users/fazepher/Dropbox/Zotero/Swendsen_Wang/Swendsen_Wang_1986_Replica_Monte_Carlo_Simulation_of_Spin-Glasses.pdf}
}

@misc{Syed.etal21,
  title = {Parallel {{Tempering}} on {{Optimized Paths}}},
  author = {Syed, Saifuddin and Romaniello, Vittorio and Campbell, Trevor and {Bouchard-C{\^o}t{\'e}}, Alexandre},
  year = {2021},
  month = jun,
  number = {arXiv:2102.07720},
  eprint = {2102.07720},
  eprinttype = {arxiv},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2102.07720},
  abstract = {Parallel tempering (PT) is a class of Markov chain Monte Carlo algorithms that constructs a path of distributions annealing between a tractable reference and an intractable target, and then interchanges states along the path to improve mixing in the target. The performance of PT depends on how quickly a sample from the reference distribution makes its way to the target, which in turn depends on the particular path of annealing distributions. However, past work on PT has used only simple paths constructed from convex combinations of the reference and target log-densities. This paper begins by demonstrating that this path performs poorly in the setting where the reference and target are nearly mutually singular. To address this issue, we expand the framework of PT to general families of paths, formulate the choice of path as an optimization problem that admits tractable gradient estimates, and propose a flexible new family of spline interpolation paths for use in practice. Theoretical and empirical results both demonstrate that our proposed methodology breaks previously-established upper performance limits for traditional paths.},
  archiveprefix = {arXiv},
  keywords = {65C05,Statistics - Computation},
  file = {/Users/fazepher/Dropbox/Zotero/Syed EtAl/Syed_EtAl_2021_Parallel_Tempering_on_Optimized_Paths.pdf}
}

@article{Syed.etal22,
  title = {Non-Reversible Parallel Tempering: {{A}} Scalable Highly Parallel {{MCMC}} Scheme},
  shorttitle = {Non-Reversible Parallel Tempering},
  author = {Syed, Saifuddin and {Bouchard-C{\^o}t{\'e}}, Alexandre and Deligiannidis, George and Doucet, Arnaud},
  year = {2022},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {84},
  number = {2},
  pages = {321--350},
  issn = {1467-9868},
  doi = {10.1111/rssb.12464},
  abstract = {Parallel tempering (PT) methods are a popular class of Markov chain Monte Carlo schemes used to sample complex high-dimensional probability distributions. They rely on a collection of N interacting auxiliary chains targeting tempered versions of the target distribution to improve the exploration of the state space. We provide here a new perspective on these highly parallel algorithms and their tuning by identifying and formalizing a sharp divide in the behaviour and performance of reversible versus non-reversible PT schemes. We show theoretically and empirically that a class of non-reversible PT methods dominates its reversible counterparts and identify distinct scaling limits for the non-reversible and reversible schemes, the former being a piecewise-deterministic Markov process and the latter a diffusion. These results are exploited to identify the optimal annealing schedule for non-reversible PT and to develop an iterative scheme approximating this schedule. We provide a wide range of numerical examples supporting our theoretical and methodological contributions. The proposed methodology is applicable to sample from a distribution {$\pi$} with a density L with respect to a reference distribution {$\pi$}0 and compute the normalizing constant {$\int$}Ld{$\pi$}0. A typical use case is when {$\pi$}0 is a prior distribution, L a likelihood function and {$\pi$} the corresponding posterior distribution.},
  langid = {english},
  keywords = {annealing schedule optimization,Markov Chain Monte Carlo,parallel computing,parallel tempering,weak convergence},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12464},
  file = {/Users/fazepher/Dropbox/Zotero/Syed EtAl/Syed et al. - 2022 - Non-reversible parallel tempering A scalable high.pdf;/Users/fazepher/Dropbox/Zotero/Syed EtAl/Syed_EtAl_2022_Non-reversible_parallel_tempering5.pdf}
}

@article{Tawn.etal20,
  title = {Weight-Preserving Simulated Tempering},
  author = {Tawn, Nicholas G. and Roberts, Gareth O. and Rosenthal, Jeffrey S.},
  year = {2020},
  month = feb,
  journal = {Statistics and Computing},
  volume = {30},
  number = {1},
  pages = {27--41},
  issn = {1573-1375},
  doi = {10.1007/s11222-019-09863-3},
  abstract = {Simulated tempering is a popular method of allowing MCMC algorithms to move between modes of a multimodal target density \$\$\textbackslash pi \$\$. One problem with simulated tempering for multimodal targets is that the weights of the various modes change for different inverse-temperature values, sometimes dramatically so. In this paper, we provide a fix to overcome this problem, by adjusting the mode weights to be preserved (i.e. constant) over different inverse-temperature settings. We then apply simulated tempering algorithms to multimodal targets using our mode weight correction. We present simulations in which our weight-preserving algorithm mixes between modes much more successfully than traditional tempering algorithms. We also prove a diffusion limit for an version of our algorithm, which shows that under appropriate assumptions, our algorithm mixes in time \$\$O(d [\textbackslash log d]\^2)\$\$.},
  langid = {english},
  keywords = {MCMC,Multimodality and Monte Carlo,Parallel tempering,Simulated tempering},
  file = {/Users/fazepher/Dropbox/Zotero/Tawn EtAl/Tawn_EtAl_2020_Weight-preserving_simulated_tempering.pdf}
}

@article{Tawn.etal21,
  title = {Annealed {{Leap-Point Sampler}} for {{Multimodal Target Distributions}}},
  author = {Tawn, Nicholas G. and Moores, Matthew T. and Roberts, Gareth O.},
  year = {2021},
  month = dec,
  journal = {arXiv:2112.12908 [stat]},
  eprint = {2112.12908},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {In Bayesian statistics, exploring multimodal posterior distribution poses major challenges for existing techniques such as Markov Chain Monte Carlo (MCMC). These problems are exacerbated in high-dimensional settings where MCMC methods typically rely upon localised proposal mechanisms. This paper introduces the Annealed Leap-Point Sampler (ALPS), which augments the target distribution state space with modified annealed (cooled) target distributions, in contrast to traditional approaches which have employed tempering. The temperature of the coldest state is chosen such that its corresponding annealed target density can be sufficiently well-approximated by a Laplace approximation. As a result, a Gaussian mixture independence Metropolis-Hastings sampler can perform mode-jumping proposals even in high-dimensional problems. The ability of this procedure to "mode hop" at this super-cold state is then filtered through to the target state using a sequence of tempered targets in a similar way to that in parallel tempering methods. ALPS also incorporates the best aspects of current gold-standard approaches to multimodal sampling in high-dimensional contexts. A theoretical analysis of the ALPS approach in high dimensions is given, providing practitioners with a gauge on the optimal setup as well as the scalability of the algorithm. For a \$d\$-dimensional problem the it is shown that the coldest inverse temperature level required for the ALPS only needs to be linear in the dimension, \$\textbackslash mathcal\{O\}(d)\$, and this means that for a collection of multimodal problems the algorithmic cost is polynomial, \$\textbackslash mathcal\{O\}\textbackslash left(d\^\{3\}\textbackslash right)\$. ALPS is illustrated on a complex multimodal posterior distribution that arises from a seemingly-unrelated regression (SUR) model of longitudinal data from U.S. manufacturing firms.},
  archiveprefix = {arXiv},
  keywords = {62-08 (Primary) 60J22; 62-04 (Secondary),Statistics - Computation,Statistics - Methodology},
  file = {/Users/fazepher/Dropbox/Zotero/Tawn EtAl/Tawn_EtAl_2021_Annealed_Leap-Point_Sampler_for_Multimodal_Target_Distributions.pdf}
}

@article{Tawn.Roberts19,
  title = {Accelerating Parallel Tempering: {{Quantile}} Tempering Algorithm ({{QuanTA}})},
  shorttitle = {Accelerating Parallel Tempering},
  author = {Tawn, Nicholas G. and Roberts, Gareth O.},
  year = {2019},
  month = sep,
  journal = {Advances in Applied Probability},
  volume = {51},
  number = {3},
  pages = {802--834},
  publisher = {{Cambridge University Press}},
  issn = {0001-8678, 1475-6064},
  doi = {10.1017/apr.2019.35},
  abstract = {It is well known that traditional Markov chain Monte Carlo (MCMC) methods can fail to effectively explore the state space for multimodal problems. Parallel tempering is a well-established population approach for such target distributions involving a collection of particles indexed by temperature. However, this method can suffer dramatically from the curse of dimensionality. In this paper we introduce an improvement on parallel tempering called QuanTA. A comprehensive theoretical analysis quantifying the improved efficiency and scalability of the approach is given. Under weak regularity conditions, QuanTA gives accelerated mixing through the temperature space. Empirical evidence of the effectiveness of this new algorithm is illustrated on canonical examples.},
  langid = {english},
  keywords = {65C60,accelerated MCMC,Markov chain Monte Carlo,Metropolis-coupled MCMC,multimodal,Parallel tempering,population MCMC,Primary 60J22,Secondary 65C05},
  file = {/Users/fazepher/Dropbox/Zotero/Tawn_Roberts/Tawn_Roberts_2019_Accelerating_parallel_tempering.pdf}
}

@phdthesis{Tawn17,
  title = {Towards Optimality of the Parallel Tempering Algorithm},
  author = {Tawn, Nicholas},
  year = {2017},
  month = sep,
  abstract = {Markov Chain Monte Carlo (MCMC) techniques for sampling from complex probability distributions have become mainstream. Big data and high model complexity demand more scalable and robust algorithms. A famous problem with MCMC is making it robust to situations when the target distribution is multi-modal. In such cases the algorithm can become trapped in a subset of the state space and fail to escape during the entirety of the run of the algorithm. This non-exploration of the state space results in highly biased sample output. Simulated (ST) and Parallel (PT) Tempering algorithms are typically used to address multi-modality problems. These methods flatten out the target distribution using a temperature schedule. This allows the Markov chain to move freely around the state space and explore all regions of significant mass. This thesis explores two new ideas to improve the scalability of the PT algorithm. These are implemented in prototype algorithms, QuanTA and HAT, which are accompanied by supportive theoretical optimal scaling results.  QuanTA focuses on improving transfer speed of the hot state mixing information to the target cold state. The associated scaling result for QuanTA shows that under mild conditions the QuanTA approach admits a higher order temperature spacing than the PT algorithm. HAT focuses on preserving modal weight through the temperature schedule. This is an issue that can lead to critically poor performance of the PT approach. The associated optimal scaling result is useful from a practical perspective. The result also challenges the notion that without modal weight preservation tempering schedules can be selected based on swap acceptance rates; an idea repeatedly used in the current literature. The new algorithms are prototype designs and have clear limitations. However, the impressive empirical performance of these new algorithms, together with supportive theory, illustrate their substantial improvement over existing methodology.},
  school = {University of Warwick},
  file = {/Users/fazepher/Dropbox/Zotero/Tawn/Tawn_2017_Towards_optimality_of_the_parallel_tempering_algorithm.pdf}
}

@article{Tjelmeland.Hegstad01,
  title = {Mode {{Jumping Proposals}} in {{MCMC}}},
  author = {Tjelmeland, Hakon and Hegstad, Bjorn Kare},
  year = {2001},
  journal = {Scandinavian Journal of Statistics},
  volume = {28},
  number = {1},
  pages = {205--223},
  issn = {1467-9469},
  doi = {10.1111/1467-9469.00232},
  abstract = {Markov chain Monte Carlo algorithms generate samples from a target distribution by simulating a Markov chain. Large flexibility exists in specification of transition matrix of the chain. In practice, however, most algorithms used only allow small changes in the state vector in each iteration. This choice typically causes problems for multi-modal distributions as moves between modes become rare and, in turn, results in slow convergence to the target distribution. In this paper we consider continuous distributions on Rn and specify how optimization for local maxima of the target distribution can be incorporated in the specification of the Markov chain. Thereby, we obtain a chain with frequent jumps between modes. We demonstrate the effectiveness of the approach in three examples. The first considers a simple mixture of bivariate normal distributions, whereas the two last examples consider sampling from posterior distributions based on previously analysed data sets.},
  langid = {english},
  keywords = {Markov chain Monte Carlo,Metropolis–Hastings,multi-model distributions,optimization},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9469.00232},
  file = {/Users/fazepher/Dropbox/Zotero/Tjelmeland_Hegstad/Tjelmeland_Hegstad_2001_Mode_Jumping_Proposals_in_MCMC.pdf}
}

@article{Vehtari.etal21,
  title = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}: {{An Improved R\textasciicircum}} for {{Assessing Convergence}} of {{MCMC}} (with {{Discussion}})},
  shorttitle = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}},
  author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = jun,
  journal = {Bayesian Analysis},
  volume = {16},
  number = {2},
  pages = {667--718},
  publisher = {{International Society for Bayesian Analysis}},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/20-BA1221},
  abstract = {Markov chain Monte Carlo is a key computational tool in Bayesian statistics, but it can be challenging to monitor the convergence of an iterative stochastic algorithm. In this paper we show that the convergence diagnostic R\textasciicircum{} of Gelman and Rubin (1992) has serious flaws. Traditional R\textasciicircum{} will fail to correctly diagnose convergence failures when the chain has a heavy tail or when the variance varies across the chains. In this paper we propose an alternative rank-based diagnostic that fixes these problems. We also introduce a collection of quantile-based local efficiency measures, along with a practical approach for computing Monte Carlo error estimates for quantiles. We suggest that common trace plots should be replaced with rank plots from multiple chains. Finally, we give recommendations for how these methods should be used in practice.},
  file = {/Users/fazepher/Dropbox/Zotero/Vehtari EtAl/Vehtari_EtAl_2021_Rank-Normalization,_Folding,_and_Localization.pdf}
}

@book{Wilkinson21,
  title = {Statistical {{Computing}}},
  author = {Wilkinson, Darren},
  year = {2021},
  month = dec,
  series = {{{APTS}}},
  address = {{Coventry, UK}},
  file = {/Users/fazepher/Dropbox/Zotero/Wilkinson/Wilkinson_2021_Statistical_Computing.pdf}
}

@article{Wu.Robert20,
  title = {Coordinate Sampler: A Non-Reversible {{Gibbs-like MCMC}} Sampler},
  shorttitle = {Coordinate Sampler},
  author = {Wu, Changye and Robert, Christian P.},
  year = {2020},
  month = may,
  journal = {Statistics and Computing},
  volume = {30},
  number = {3},
  pages = {721--730},
  issn = {1573-1375},
  doi = {10.1007/s11222-019-09913-w},
  abstract = {We derive a novel non-reversible, continuous-time Markov chain Monte Carlo sampler, called Coordinate Sampler, based on a piecewise deterministic Markov process, which is a variant of the Zigzag sampler of Bierkens et al. (Ann Stat 47(3):1288\textendash 1320, 2019). In addition to providing a theoretical validation for this new simulation algorithm, we show that the Markov chain it induces exhibits geometrical ergodicity convergence, for distributions whose tails decay at least as fast as an exponential distribution and at most as fast as a Gaussian distribution. Several numerical examples highlight that our coordinate sampler is more efficient than the Zigzag sampler, in terms of effective sample size.},
  langid = {english},
  keywords = {Gibbs sampling,Markov chain Monte Carlo,Piecewise deterministic Markov processes,Zigzag sampling},
  file = {/Users/fazepher/Dropbox/Zotero/Wu_Robert/Wu_Robert_2020_Coordinate_sampler.pdf}
}

@article{Yang.Rodriguez13,
  title = {Searching for Efficient {{Markov}} Chain {{Monte Carlo}} Proposal Kernels},
  author = {Yang, Ziheng and Rodr{\'i}guez, Carlos E.},
  year = {2013},
  month = nov,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {48},
  pages = {19307--19312},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1311790110},
  file = {/Users/fazepher/Dropbox/Zotero/Yang_Rodriguez/Yang_Rodriguez_2013_Searching_for_efficient_Markov_chain_Monte_Carlo_proposal_kernels.pdf}
}

@article{Yao.etal22,
  title = {Stacking for {{Non-mixing Bayesian Computations}}: {{The Curse}} and {{Blessing}} of {{Multimodal Posteriors}}},
  shorttitle = {Stacking for {{Non-mixing Bayesian Computations}}},
  author = {Yao, Yuling and Vehtari, Aki and Gelman, Andrew},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {79},
  pages = {1--45},
  issn = {1533-7928},
  abstract = {When working with multimodal Bayesian posterior distributions, Markov chain Monte Carlo (MCMC) algorithms have difficulty moving between modes, and default variational or mode-based approximate inferences will understate posterior uncertainty. And, even if the most important modes can be found, it is difficult to evaluate their relative weights in the posterior. Here we propose an approach using parallel runs of MCMC, variational, or mode-based inference to hit as many modes or separated regions as possible and then combine these using Bayesian stacking, a scalable method for constructing a weighted average of distributions. The result from stacking efficiently samples from multimodal posterior distribution, minimizes cross validation prediction error, and represents the posterior uncertainty better than variational inference, but it is not necessarily equivalent, even asymptotically, to fully Bayesian inference. We present theoretical consistency with an example where the stacked inference approximates the true data generating process from the misspecified model and a non-mixing sampler, from which the predictive performance is better than full Bayesian inference, hence the multimodality can be considered a blessing rather than a curse under model misspecification. We demonstrate practical implementation in several model families: latent Dirichlet allocation, Gaussian process regression, hierarchical regression, horseshoe variable selection, and neural networks.},
  file = {/Users/fazepher/Dropbox/Zotero/Yao EtAl/Yao_EtAl_2022_Stacking_for_Non-mixing_Bayesian_Computations.pdf}
}

@article{Zhou11,
  title = {Multi-{{Domain Sampling With Applications}} to {{Structural Inference}} of {{Bayesian Networks}}},
  author = {Zhou, Qing},
  year = {2011},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {106},
  number = {496},
  pages = {1317--1330},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/jasa.2011.ap10346},
  langid = {english},
  file = {/Users/fazepher/Dropbox/Zotero/Zhou/Zhou_2011_Multi-Domain_Sampling_With_Applications_to_Structural_Inference_of_Bayesian.pdf}
}


